---
title: "Project 2"
author: "Simon Kauppinen"
output:
  html_document:
   toc: true
   css: synthwave84-rmd.css
---
# Chapter 12 Problem 10

a\)

```{r}
set.seed(1)              # for reproducibility

X <- matrix(rnorm(20*3*50), nrow = 60, ncol = 50) # 60x50 Matrix with random values from standard normal distribution.
X[1:20, ] <- X[1:20,] + 2   # class 1 centered around mean 2
X[21:40, ] <- X[21:40,] -2   # class 2 centered around mean -2
# class 3 left with mean 0

```


b\) 

```{r}
# Performs PCA with scaling
pr.out <- prcomp(X, scale. = TRUE)

# Colors for each class
cls <- rep(c("red", "blue", "green"), each = 20)

# Plot first two principal components colored by true class
plot(pr.out$x[,1], pr.out$x[,2], col = cls, pch = 19,
     xlab = "PC1", ylab = "PC2",
     main = "PCA: First Two Principal Components")
```

c\)

```{r}
set.seed(1)
km.out <- kmeans(X, 3, nstart = 20)  
table(Predicted = km.out$cluster, True = rep(1:3, each = 20))
```

From the table we can see that the clustering correctly groups observations even though the cluster labels are not aligned with the class labels.

```{r message=FALSE, warning=FALSE}
library("StratigrapheR")
# Shift cluster labels to align with class labels
km.out$cluster <- shift(km.out$cluster, n=20)
table(Predicted=km.out$cluster, True= rep(1:3, each=20))
```


```{r}
# True class vector and color function
class_vec <- rep(1:3, each = 20)
Cols <- function(x) c("red", "blue", "green")[x]

# Side-by-side plots for comparison
par(mfrow = c(1, 2))

# Left plot: True classes colored by actual labels
plot(pr.out$x[, 1:2],
     col = Cols(class_vec),
     pch = 19,
     xlab = "PC1", ylab = "PC2",
     main = "True Classes")

# Right plot: K-means clustering results colored by cluster assignment
plot(pr.out$x[, 1:2],
     col = Cols(km.out$cluster),
     pch = 19,
     xlab = "PC1", ylab = "PC2", 
     main = "K-means Clustering (K=3)")
```


d\)

```{r}
# Perform K-means clustering with K=2 (fewer than true classes)
set.seed(1)
km.out <- kmeans(X, 2, nstart = 20)

# Side-by-side plots
par(mfrow = c(1, 2))

# Left plot: True classes (3 classes)
plot(pr.out$x[, 1:2],
     col = Cols(class_vec),
     pch = 19,
     xlab = "PC1", ylab = "PC2",
     main = "True Classes (3)")

# Right plot: K-means with K=2 (clusters forced into 2 groups)
plot(pr.out$x[, 1:2],
     col = Cols(km.out$cluster),
     pch = 19,
     xlab = "PC1", ylab = "PC2",
     main = "K-means Clustering (K=2)")
```

Here we can see that the K-means clustering grouped observations in the first class as one cluster and the last two classes as the second cluster.

e\)

```{r}
set.seed(1)
km.out <- kmeans(X, 4, nstart = 20)
Cols2 <- function(x)c("red", "blue", "green","brown")[x] # One color for each cluster label

# Side-by-side plots
par(mfrow = c(1, 2))

# Left plot: True classes (3 classes)
plot(pr.out$x[, 1:2],
     col = Cols(class_vec),
     pch = 19,
     xlab = "PC1", ylab = "PC2", 
     main = "True Classes (3)")

# Right plot: K-means with K=4
plot(pr.out$x[, 1:2],
     col = Cols2(km.out$cluster),
     pch = 19,
     xlab = "PC1", ylab = "PC2",
     main = "K-means Clustering (K=4)")
```

Here we can see that the second and third classes were correctly grouped into own clusters and the first class was split between the remaining two clusters.